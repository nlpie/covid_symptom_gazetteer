{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import csv\n",
    "import scispacy\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "from scispacy.linking import EntityLinker\n",
    "import en_core_web_lg as lg\n",
    "import en_core_sci_lg as scilg\n",
    "import en_core_sci_sm as scism\n",
    "from negspacy.negation import Negex\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.matcher import Matcher\n",
    "from sqlalchemy.engine import create_engine\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    new_text = re.sub('[^A-Za-z0-9 /-]+', '', text.lower())\n",
    "    cl_text = re.sub(r'(?:(?<=\\/) | (?=\\/))','',new_text)\n",
    "    #print('{}: {}'.format(cl_text, len(cl_text)))\n",
    "    return cl_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_words(words):\n",
    "    \n",
    "    new_text = words[0]\n",
    "    special = ['-', '/']\n",
    "    for i in range(1, len(words)):\n",
    "        if words[i] in special or words[i-1] in special:\n",
    "            new_text = new_text + words[i]\n",
    "        else:\n",
    "            new_text = new_text + ' ' + words[i]\n",
    "        \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(_dict, output):\n",
    "    \n",
    "    with open(output, 'w') as csv_file:  \n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in _dict.items():\n",
    "            writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv_pos_neg_final(_dict_positive, _dict_negative, _dict_final, output):\n",
    "    \n",
    "    cdc_symptoms = ['cough', 'shortness of breath or difficulty breathing', 'fatigue', 'headache', \n",
    "                    'ache', 'new loss of taste or smell', 'sore throat', 'congestion or runny nose', \n",
    "                    'nausea or vomit', 'diarrhea', 'fever or chill']\n",
    "    \n",
    "    new_cdc_symptoms = ['file_id']\n",
    "    for x in cdc_symptoms:\n",
    "        words_pos = x.split()\n",
    "        words_pos.append('p')\n",
    "        words_neg = x.split()\n",
    "        words_neg.append('n')\n",
    "        words_neutral = x.split()\n",
    "        \n",
    "        new_pos = '_'.join(words_pos)\n",
    "        new_neg = '_'.join(words_neg)\n",
    "        new_neutral = '_'.join(words_neutral)\n",
    "        \n",
    "        new_cdc_symptoms.append(new_pos)\n",
    "        new_cdc_symptoms.append(new_neutral)\n",
    "        new_cdc_symptoms.append(new_neg)\n",
    "        \n",
    "    with open(output, 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(new_cdc_symptoms)\n",
    "        \n",
    "        for key, value in _dict_positive.items():\n",
    "            li_men = [key]\n",
    "            for key2, value2 in value.items():\n",
    "                li_men.extend([_dict_positive[key][key2], _dict_final[key][key2], _dict_negative[key][key2]])\n",
    "            writer.writerow(li_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dict(_dict, notes_for_training, dict_gold_cdc_cui):\n",
    "    \n",
    "    for file in notes_for_training:\n",
    "        #name = file.replace('.source', '')\n",
    "        name = file.strip()\n",
    "        for k, v in dict_gold_cdc_cui.items():\n",
    "            _dict[name][k] = 0\n",
    "    \n",
    "    #print(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses a dictionary of list\n",
    "def check_dict(_dict, element):\n",
    "    \n",
    "    for k, v in _dict.items():\n",
    "        if element in v:\n",
    "            return k\n",
    "    \n",
    "    return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mdict(_dict, file, parent):\n",
    "\n",
    "    _dict[file][parent] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_final_mdict(_dict_final, _dict_positive, _dict_negative):\n",
    "    \n",
    "    for key, value in _dict_final.items():\n",
    "        for key2, value2 in value.items():\n",
    "            pos = _dict_positive[key][key2]\n",
    "            neg = _dict_negative[key][key2]\n",
    "            \n",
    "            if (pos == 1):\n",
    "                _dict_final[key][key2] = 1\n",
    "            if (pos == 0) and (neg == 1):\n",
    "                _dict_final[key][key2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(li1, li2):\n",
    "\n",
    "    li_dif = []\n",
    "    for x in li1:\n",
    "        if x not in li2:\n",
    "            li_dif.append(x)\n",
    "            \n",
    "    return li_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gaz_cdc(filename):\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    _dict = defaultdict(list)\n",
    "    \n",
    "    with open(filename, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            new_list = []\n",
    "            for x in row:\n",
    "                x_new = clean_text(x)\n",
    "                words = [token.lemma_ for token in nlp(x_new.strip())]\n",
    "                new_str = join_words(words)\n",
    "                #print('{}: {}'.format(new_str, len(new_str)))\n",
    "                new_list.append(new_str)\n",
    "            _dict[new_list[1]].append(new_list[0])\n",
    "            #if new_list[1] not in _dict[new_list[1]]:\n",
    "            #    _dict[new_list[1]].append(new_list[1])\n",
    "    \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gazetteer(filename):\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    gaz = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            row_0_new = clean_text(row[0])\n",
    "            row_1_new = clean_text(row[1])\n",
    "            \n",
    "            words_0 = [token.lemma_ for token in nlp(row_0_new.strip())]\n",
    "            new_str_0 = join_words(words_0)\n",
    "            words_1 = [token.lemma_ for token in nlp(row_1_new.strip())]\n",
    "            new_str_1 = join_words(words_1)\n",
    "            \n",
    "            if new_str_0 not in gaz:\n",
    "                gaz.append(new_str_0)\n",
    "            if new_str_1 not in gaz:\n",
    "                gaz.append(new_str_1)\n",
    "    \n",
    "    return gaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaz_matches(tokenizer, phrases, texts, span_left, span_right):\n",
    "    matcher = PhraseMatcher(tokenizer.vocab)\n",
    "    matcher.add(\"Phrase\", None, *phrases)\n",
    "    for text in texts:\n",
    "        doc = tokenizer(text.lower())\n",
    "        for w in doc:\n",
    "            _ = doc.vocab[w.text]\n",
    "        matches = matcher(doc)\n",
    "        for ent_id, start, end in matches:\n",
    "            if start - span_left >= 0:\n",
    "                yield (ent_id, doc[start:end].text, doc[(start - span_left):(end + span_right)].text)\n",
    "            else:\n",
    "                yield (ent_id, doc[start:end].text, doc[start:(end + span_right)].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matcher(nlp):\n",
    "    \n",
    "    patterns = [[{'LEMMA': 'abdominal'}, {'LEMMA': 'bloating'}],\n",
    "                [{'LEMMA': 'abdominal'}, {'LEMMA': 'bloat'}],\n",
    "                [{'LEMMA': 'abdominal'}, {'LEMMA': 'cramping'}],\n",
    "                [{'LEMMA': 'abdominal'}, {'LEMMA': 'cramp'}],\n",
    "                [{'LEMMA': 'abdominal'}, {'LEMMA': 'pain'}],\n",
    "                ############## possible variations ############\n",
    "                [{'LEMMA': 'stomach'}, {'LEMMA': 'pain'}],\n",
    "                [{'LEMMA': 'stomach'}, {'LEMMA': 'bloating'}],\n",
    "                [{'LEMMA': 'stomach'}, {'LEMMA': 'bloat'}],\n",
    "                [{'LEMMA': 'stomach'}, {'LEMMA': 'cramping'}],\n",
    "                [{'LEMMA': 'stomach'}, {'LEMMA': 'cramp'}],\n",
    "                [{'LEMMA': 'gastric'}, {'LEMMA': 'bloating'}],\n",
    "                [{'LEMMA': 'gastric'}, {'LEMMA': 'bloat'}],\n",
    "                [{'LEMMA': 'gastric'}, {'LEMMA': 'cramping'}],\n",
    "                [{'LEMMA': 'gastric'}, {'LEMMA': 'cramp'}],\n",
    "                [{'LEMMA': 'gastric'}, {'LEMMA': 'pain'}],\n",
    "                ###############################################\n",
    "                [{'LEMMA': 'ache'}, {'POS': 'CCONJ'}, {'LEMMA': 'pain'}],\n",
    "                [{'LEMMA': 'achey'}], \n",
    "                [{'LEMMA': 'achiness'}],\n",
    "                [{'LEMMA': 'achy'}],\n",
    "                [{'LEMMA': 'asthenia'}],\n",
    "                [{'LEMMA': 'calf'}, {'LEMMA': 'pain'}],\n",
    "                ############# use case: can't and cannot ############\n",
    "                [{'LEMMA': 'can'}, {'LEMMA': 'not'}, {'LEMMA': 'breathe'}], \n",
    "                [{'LEMMA': 'can'}, {'LEMMA': 'not'}, {'LEMMA': 'smell'}],\n",
    "                [{'LEMMA': 'can'}, {'LEMMA': 'not'}, {'LEMMA': 'taste'}],\n",
    "                #####################################################\n",
    "                [{'LOWER': 'catharsis'}],\n",
    "                [{'LEMMA': 'cephalic'}, {'LEMMA': 'pain'}],\n",
    "                [{'LEMMA': 'congested'}]\n",
    "                [{'LEMMA': 'congestion'}, {'POS': 'CCONJ'}, {'LEMMA': 'runny'}, {'LEMMA': 'nose'}],\n",
    "                [{'LEMMA': 'cramp'}],\n",
    "                [{'LEMMA': 'diaphoretic'}],\n",
    "                [{'LEMMA': 'discombobulation'}],\n",
    "                [{'LEMMA': 'distaste'}],\n",
    "                [{'LEMMA': 'doe'}],\n",
    "                [{'LEMMA': 'dysphagia'}],\n",
    "                [{'LEMMA': 'elevated'}, {'LEMMA': 'temp'}],\n",
    "                ############## possible variations. use cases: high, higher ############\n",
    "                [{'LEMMA': 'high'}, {'LEMMA': 'temp'}],\n",
    "                [{'LEMMA': 'elevated'}, {'LEMMA': 'temperature'}],\n",
    "                [{'LEMMA': 'high'}, {'LEMMA': 'temperature'}],\n",
    "                ########################################################################\n",
    "                [{'LEMMA': 'exhaustion'}],\n",
    "                [{'LOWER': 'f'}, {'IS_PUNCT': True}, {'LOWER': 'c'}],\n",
    "                [{'LEMMA': 'febrile'}],\n",
    "                [{'LEMMA': 'fever'}, {'POS': 'CCONJ'}, {'LEMMA': 'chill'}],\n",
    "                [{'LEMMA': 'food'}, {'LEMMA': 'aversion'}],\n",
    "                [{'LEMMA': 'gag'}],\n",
    "                [{'LEMMA': 'gi'}, {'LEMMA': 'symptom'}],\n",
    "                [{'LEMMA': 'headache'}],\n",
    "                [{'LEMMA': 'hyperthermia'}],\n",
    "                [{'LEMMA': 'inspiratory'}, {'LEMMA': 'pain'}],\n",
    "                [{'LEMMA': 'lack'}, {'TAG': 'IN'}, {'LEMMA': 'olfactory'}, {'LEMMA': 'sense'}],\n",
    "                [{'LEMMA': 'loose'}, {'LEMMA': 'stool'}],\n",
    "                [{'LEMMA': 'loss'}, {'TAG': 'IN'}, {'LEMMA': 'smell'}],\n",
    "                [{'LEMMA': 'loss'}, {'TAG': 'IN'}, {'LEMMA': 'taste'}],\n",
    "                [{'LEMMA': 'low'}, {'LEMMA': 'energy'}],\n",
    "                [{'LEMMA': 'metallic'}, {'LEMMA': 'taste'}],\n",
    "                ############## possible variation ############\n",
    "                [{'LEMMA': 'metal'}, {'LEMMA': 'taste'}],\n",
    "                ###############################################\n",
    "                [{'LEMMA': 'mucusy'}],\n",
    "                [{'LEMMA': 'muscle'}, {'LEMMA': 'pain'}],\n",
    "                [{'LEMMA': 'myalgia'}],\n",
    "                [{'LEMMA': 'myodynia'}],\n",
    "                [{'LOWER': 'n'}, {'IS_PUNCT': True}, {'LOWER': 'v'}],\n",
    "                [{'LEMMA': 'nausea'}, {'POS': 'CCONJ'}, {'LEMMA': 'vomit'}],\n",
    "                ############## possible variation ############\n",
    "                [{'LEMMA': 'nauseous'}],\n",
    "                ##############################################\n",
    "                [{'LEMMA': 'neck'}, {'LEMMA': 'pain'}],\n",
    "                [{'LEMMA': 'new'}, {'LEMMA': 'loss'}, {'POS': 'ADP', 'TAG': 'IN'}, {'LEMMA': 'taste'}, {'POS': 'CCONJ', 'TAG': 'CC'}, {'LEMMA': 'smell'}],\n",
    "                [{'LEMMA': 'not', 'TAG': 'RB'}, {'LEMMA': 'eat'}],\n",
    "                [{'LEMMA': 'not', 'TAG': 'RB'}, {'LEMMA': 'hungry'}],\n",
    "                [{'LEMMA': 'out'}, {'LEMMA': 'of', 'TAG': 'IN'}, {'LOWER': 'it', 'TAG': 'PRP'}],\n",
    "                [{'LEMMA': 'pain'}, {'LEMMA': 'with', 'POS': 'ADP'}, {'LEMMA': 'inspiration'}],\n",
    "                [{'LEMMA': 'painful'}, {'LEMMA': 'swallow'}],\n",
    "                [{'LEMMA': 'pleurisy'}],\n",
    "                [{'LOWER': 'pnd'}],\n",
    "                [{'LEMMA': 'poor'}, {'LEMMA': 'appetite'}],\n",
    "                [{'LOWER': 'purgation'}],\n",
    "                [{'LEMMA': 'queasiness'}],\n",
    "                [{'LEMMA': 'queasy'}],\n",
    "                [{'LEMMA': 'respiratory'}, {'LEMMA': 'difficulty'}],\n",
    "                [{'LEMMA': 'respiratory'}, {'LEMMA': 'distress'}],\n",
    "                [{'LEMMA': 'retch'}],\n",
    "                [{'LEMMA': 'rhinorrhea'}],\n",
    "                [{'LEMMA': 'rigor'}],\n",
    "                [{'LEMMA': 'rhinorrhea'}],\n",
    "                [{'LEMMA': 'runny'}, {'LEMMA': 'nose'}],\n",
    "                [{'LEMMA': 'scratchy'}, {'LEMMA': 'throat'}],\n",
    "                [{'LEMMA': 'shake'}],\n",
    "                [{'LEMMA': 'shakey'}],\n",
    "                [{'LEMMA': 'shakiness'}],\n",
    "                [{'LEMMA': 'short'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}],\n",
    "                [{'LEMMA': 'shortness'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}],\n",
    "                [{'LEMMA': 'shortness'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}, {'POS': 'CCONJ'}, {'LEMMA': 'difficulty'}, {'LEMMA': 'breathing'}],\n",
    "                ############## possible variation ############\n",
    "                [{'LEMMA': 'short'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}, {'POS': 'CCONJ'}, {'LEMMA': 'difficulty'}, {'LEMMA': 'breathing'}],\n",
    "                ##############################################\n",
    "                [{'LEMMA': 'sob'}],\n",
    "                [{'LEMMA': 'sore'}, {'LEMMA': 'throat'}],\n",
    "                [{'LEMMA': 'soreness'}],\n",
    "                [{'LEMMA': 'stuffy'}, {'LEMMA': 'nose'}],\n",
    "                [{'LEMMA': 'sweaty'}],\n",
    "                ############## possible variation ############\n",
    "                [{'LEMMA': 'sweat'}],\n",
    "                [{'LEMMA': 'sweating'}],\n",
    "                ##############################################\n",
    "                [{'LEMMA': 'throw'}, {'LEMMA': 'up'}],\n",
    "                [{'LOWER': 'tired'}], \n",
    "                [{'LOWER': 'tiredness'}],\n",
    "                [{'LOWER': 'tremor'}],\n",
    "                [{'LOWER': 'trot'}],\n",
    "                [{'LEMMA': 'trouble'}, {'LEMMA': 'breathing'}],\n",
    "                [{'LEMMA': 'watery'}, {'LEMMA': 'stool'}],\n",
    "                [{'LEMMA': 'weariness'}],\n",
    "                [{'LEMMA': 'wear'}, {'LEMMA': 'out'}]\n",
    "                ]\n",
    "    \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    count = 0\n",
    "    for pattern in patterns:\n",
    "        matcher.add(pattern[0].items()[1], None, pattern)\n",
    "        count = count + 1\n",
    "    \n",
    "    print('patterns added: {}'.format(count))\n",
    "    \n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ruler(nlp):\n",
    "    \n",
    "    patterns = [ {'label': 'ENTITY', 'pattern': [{'LEMMA': 'abdominal'}, {'LEMMA': 'bloating'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'abdominal'}, {'LEMMA': 'bloat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'abdominal'}, {'LEMMA': 'cramping'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'abdominal'}, {'LEMMA': 'cramp'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'abdominal'}, {'LEMMA': 'pain'}]},\n",
    "                 ############## possible variations ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'stomach'}, {'LEMMA': 'pain'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'stomach'}, {'LEMMA': 'bloating'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'stomach'}, {'LEMMA': 'bloat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'stomach'}, {'LEMMA': 'cramping'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'stomach'}, {'LEMMA': 'cramp'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gastric'}, {'LEMMA': 'bloating'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gastric'}, {'LEMMA': 'bloat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gastric'}, {'LEMMA': 'cramping'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gastric'}, {'LEMMA': 'cramp'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gastric'}, {'LEMMA': 'pain'}]},\n",
    "                 ###############################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'ache'}, {'POS': 'CCONJ'}, {'LEMMA': 'pain'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'achey'}]}, \n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'achiness'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'achy'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'asthenia'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'calf'}, {'LEMMA': 'pain'}]},\n",
    "                 ############# use case: can't and cannot ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'can'}, {'LEMMA': 'not'}, {'LEMMA': 'breathe'}]}, \n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'can'}, {'LEMMA': 'not'}, {'LEMMA': 'smell'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'can'}, {'LEMMA': 'not'}, {'LEMMA': 'taste'}]},\n",
    "                 #####################################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'catharsis'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'cephalic'}, {'LEMMA': 'pain'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'congested'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'congestion'}, {'POS': 'CCONJ'}, {'LEMMA': 'runny'}, {'LEMMA': 'nose'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'cramp'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'diaphoretic'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'discombobulation'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'distaste'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'doe'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'dysphagia'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'elevated'}, {'LEMMA': 'temp'}]},\n",
    "                 ############## possible variations. use cases: high, higher ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'high'}, {'LEMMA': 'temp'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'elevated'}, {'LEMMA': 'temperature'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'high'}, {'LEMMA': 'temperature'}]},\n",
    "                 ########################################################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'exhaustion'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'f'}, {'IS_PUNCT': True}, {'LOWER': 'c'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'febrile'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'fever'}, {'POS': 'CCONJ'}, {'LEMMA': 'chill'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'food'}, {'LEMMA': 'aversion'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gag'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'gi'}, {'LEMMA': 'symptom'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'headache'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'hyperthermia'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'inspiratory'}, {'LEMMA': 'pain'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'lack'}, {'TAG': 'IN'}, {'LEMMA': 'olfactory'}, {'LEMMA': 'sense'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'loose'}, {'LEMMA': 'stool'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'loss'}, {'TAG': 'IN'}, {'LEMMA': 'smell'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'loss'}, {'TAG': 'IN'}, {'LEMMA': 'taste'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'low'}, {'LEMMA': 'energy'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'metallic'}, {'LEMMA': 'taste'}]},\n",
    "                 ############## possible variation ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'metal'}, {'LEMMA': 'taste'}]},\n",
    "                 ###############################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'mucusy'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'muscle'}, {'LEMMA': 'pain'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'myalgia'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'myodynia'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'n'}, {'IS_PUNCT': True}, {'LOWER': 'v'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'nausea'}, {'POS': 'CCONJ'}, {'LEMMA': 'vomit'}]},\n",
    "                 ############## possible variation ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'nauseous'}]},\n",
    "                 ##############################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'neck'}, {'LEMMA': 'pain'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'new'}, {'LEMMA': 'loss'}, {'POS': 'ADP', 'TAG': 'IN'}, {'LEMMA': 'taste'}, {'POS': 'CCONJ', 'TAG': 'CC'}, {'LEMMA': 'smell'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'not', 'TAG': 'RB'}, {'LEMMA': 'eat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'not', 'TAG': 'RB'}, {'LEMMA': 'hungry'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'out'}, {'LEMMA': 'of', 'TAG': 'IN'}, {'LOWER': 'it', 'TAG': 'PRP'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'pain'}, {'LEMMA': 'with', 'POS': 'ADP'}, {'LEMMA': 'inspiration'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'painful'}, {'LEMMA': 'swallow'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'pleurisy'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'pnd'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'poor'}, {'LEMMA': 'appetite'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'purgation'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'queasiness'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'queasy'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'respiratory'}, {'LEMMA': 'difficulty'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'respiratory'}, {'LEMMA': 'distress'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'retch'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'rhinorrhea'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'rigor'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'rhinorrhea'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'runny'}, {'LEMMA': 'nose'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'scratchy'}, {'LEMMA': 'throat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'shake'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'shakey'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'shakiness'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'short'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'shortness'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'shortness'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}, {'POS': 'CCONJ'}, {'LEMMA': 'difficulty'}, {'LEMMA': 'breathing'}]},\n",
    "                 ############## possible variation ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'short'}, {'POS': 'ADP'}, {'LEMMA': 'breath'}, {'POS': 'CCONJ'}, {'LEMMA': 'difficulty'}, {'LEMMA': 'breathing'}]},\n",
    "                 ##############################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'sob'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'sore'}, {'LEMMA': 'throat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'soreness'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'stuffy'}, {'LEMMA': 'nose'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'sweaty'}]},\n",
    "                 ############## possible variation ############\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'sweat'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'sweating'}]},\n",
    "                 ##############################################\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'throw'}, {'LEMMA': 'up'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'tired'}]}, \n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'tiredness'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'tremor'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LOWER': 'trot'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'trouble'}, {'LEMMA': 'breathing'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'watery'}, {'LEMMA': 'stool'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'weariness'}]},\n",
    "                 {'label': 'ENTITY', 'pattern': [{'LEMMA': 'wear'}, {'LEMMA': 'out'}]}\n",
    "                ]\n",
    "    \n",
    "    ruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "    ruler.add_patterns(patterns)\n",
    "    \n",
    "    return ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gazetteer_lexicon_count_dictionary(gazetteer):\n",
    "    \n",
    "    dict_lexicon_count = defaultdict(list)\n",
    "    for x in gazetteer:\n",
    "        dict_lexicon_count[x] = 0\n",
    "    \n",
    "    return dict_lexicon_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention_using_gaz(gaz_csv, notes_for_training, doc_folder, dict_gaz, output, output_lex_count):\n",
    "    \n",
    "    nlp = spacy.blank('en')\n",
    "    nlp.vocab.lex_attr_getters = {}\n",
    "    gaz = create_gazetteer(gaz_csv)\n",
    "    patterns = [nlp.make_doc(text) for text in gaz]\n",
    "    \n",
    "    nlp_lemma = lg.load()\n",
    "    \n",
    "    dict_files_positive = defaultdict(dict)\n",
    "    init_dict(dict_files_positive, notes_for_training, dict_gaz)\n",
    "    \n",
    "    dict_files_negative = defaultdict(dict)\n",
    "    init_dict(dict_files_negative, notes_for_training, dict_gaz)\n",
    "    \n",
    "    dict_files_final = defaultdict(dict)\n",
    "    init_dict(dict_files_final, notes_for_training, dict_gaz)\n",
    "    \n",
    "    dict_lex_count = create_gazetteer_lexicon_count_dictionary(gaz)\n",
    "    \n",
    "    span_left = 10\n",
    "    span_right = 2\n",
    "    span_left_temporal = 15\n",
    "    span_right_temporal = 15\n",
    "    \n",
    "    nlp_neg = scilg.load()\n",
    "    linker = EntityLinker(resolve_abbreviations=True, name=\"umls\")\n",
    "    nlp_neg.add_pipe(linker)\n",
    "    #matcher = create_matcher(nlp_neg)\n",
    "    #nlp_neg.add_pipe(matcher)\n",
    "    ruler = create_ruler(nlp_neg)\n",
    "    nlp_neg.add_pipe(ruler)\n",
    "    negex = Negex(nlp_neg, language = \"en_clinical_sensitive\", chunk_prefix = [\"without\", \"no\"])\n",
    "    negex.add_patterns(preceding_negations = ['deny'])\n",
    "    nlp_neg.add_pipe(negex, last = True)\n",
    "    \n",
    "    for file in notes_for_training:\n",
    "        with open(os.path.join(doc_folder, file), 'r') as f:\n",
    "            for ent_id, men, text in get_gaz_matches(nlp.tokenizer, patterns, f, span_left, span_right):\n",
    "                words = [token.lemma_ for token in nlp_lemma(men.lower().strip())]\n",
    "                sent_words = [token.lemma_ for token in nlp_lemma(text.lower().strip())]\n",
    "                new_str = join_words(words)\n",
    "                new_str_sent = join_words(sent_words)\n",
    "                \n",
    "                #print(new_str)\n",
    "                # additional conditions to detect use case like: '... no fever. Patient has sore throat ...'\n",
    "                split_strings = new_str_sent.split('.')\n",
    "                for sub in split_strings:\n",
    "                    threshold = 2\n",
    "                    if (len(sub.split()) >= threshold):\n",
    "                        neg = nlp_neg(sub)\n",
    "                        for e in neg.ents:\n",
    "                            parent = check_dict(dict_gaz, e.text)\n",
    "                            if (parent != 'null'):\n",
    "                                name = file.strip()\n",
    "                                content = name + ', [' + new_str_sent + '], ' + e.text + ', ' + str(not e._.negex) + '\\n'\n",
    "                                #print(content)\n",
    "                                dict_lex_count[e.text] = dict_lex_count[e.text] + 1\n",
    "                                men_bool = not e._.negex\n",
    "                                if men_bool:\n",
    "                                    update_mdict(dict_files_positive, name, parent)\n",
    "                                if men_bool == False:\n",
    "                                    update_mdict(dict_files_negative, name, parent)\n",
    "    \n",
    "    update_final_mdict(dict_files_final, dict_files_positive, dict_files_negative)\n",
    "    write_to_csv_pos_neg_final(dict_files_positive, dict_files_negative, dict_files_final, output)\n",
    "    write_to_csv(dict_lex_count, output_lex_count)\n",
    "    \n",
    "    #print(dict_files)\n",
    "    return dict_files_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_notes_for_gaz_tuning(engine_name):\n",
    "    \n",
    "    engine = create_engine(engine_name)\n",
    "    sql = \"\"\"SELECT file\n",
    "             FROM public.training_notes\"\"\"\n",
    "    \n",
    "    training_files = pd.read_sql(sql, engine).file.to_list()\n",
    "    return training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_notes_for_gold_standard(gold_standard_notes):\n",
    "    \n",
    "    gold_notes = []\n",
    "    with open(gold_standard_notes, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            mdm_link_id, encounter_date, note_id, pat_id, note_status = row\n",
    "            gold_notes.append(pat_id + '_' + note_id + '.txt')\n",
    "    \n",
    "    gold_notes.pop(0)\n",
    "    \n",
    "    print('length of notes for gold evaluation: {}'.format(len(gold_notes)))\n",
    "    return gold_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of notes for gold evaluation: 53\n",
      "total notes including some gold notes: 1700\n",
      "total notes for training: 1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\him85144\\.conda\\envs\\gaz_covid\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\him85144\\.conda\\envs\\gaz_covid\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\him85144\\.conda\\envs\\gaz_covid\\lib\\site-packages\\scispacy\\candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]\n",
      "C:\\Users\\him85144\\.conda\\envs\\gaz_covid\\lib\\site-packages\\scispacy\\candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    gaz_csv = 'GAZ_group.csv'\n",
    "    dict_gaz_cdc = load_gaz_cdc(gaz_csv)\n",
    "    #print(dict_gaz_cdc) \n",
    "    \n",
    "    gold_standard_csv = 'Z:\\\\ed_provider_notes\\\\methods_paper\\\\gold_standard_eval\\\\annotation_metadata.csv'\n",
    "    doc_folder = 'Z:\\\\ed_provider_notes\\\\methods_paper\\\\notes_for_analysis'\n",
    "    output_gaz = 'covid_gaz_cdc_mentions.csv'\n",
    "    output_lex_count = 'covid_gaz_lexicon_count.csv'\n",
    "    engine_name = 'postgresql+psycopg2://him85144:test123@d0pconcourse001/covid-19'\n",
    "    \n",
    "    gold_standard_notes = select_notes_for_gold_standard(gold_standard_csv)\n",
    "    all_notes = select_notes_for_gaz_tuning(engine_name)\n",
    "    print('total notes including some gold notes: {}'.format(len(all_notes)))\n",
    "    training_notes = diff(all_notes, gold_standard_notes)\n",
    "    print('total notes for training: {}'.format(len(training_notes)))\n",
    "    gaz_men = mention_using_gaz(gaz_csv, training_notes, doc_folder, dict_gaz_cdc, output_gaz, output_lex_count)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
